diff --git a/CMakeLists.txt b/CMakeLists.txt
index 98166b7..70531c3 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -2,22 +2,23 @@ cmake_minimum_required(VERSION 2.8.3)
 
 project(gscam)
 
+if (${CMAKE_SYSTEM_PROCESSOR} STREQUAL "x86_64")
+    set(BUILD_CORE_NODES          OFF)
+elseif (${CMAKE_SYSTEM_PROCESSOR} STREQUAL "aarch64")
+    set(BUILD_CORE_NODES          ON CACHE BOOL "Build core nodes")
+else()
+    message(FATAL_ERROR "Unknown processor:" ${CMAKE_SYSTEM_PROCESSOR})
+endif()
+
+if(${BUILD_CORE_NODES})
+
 # System Dependencies
 find_package(PkgConfig)
 
-pkg_check_modules(GSTREAMER QUIET gstreamer-0.10)
-if(NOT GSTREAMER_FOUND)
-  set(GSTREAMER_VERSION_1_x TRUE)
-endif()
-if(GSTREAMER_VERSION_1_x)
-  message(STATUS "gst 1.0")
-  pkg_check_modules(GSTREAMER REQUIRED gstreamer-1.0)
-  pkg_check_modules(GST_APP REQUIRED gstreamer-app-1.0)
-else()
-  message(STATUS "gst 0.1")
-  pkg_check_modules(GSTREAMER REQUIRED gstreamer-0.10)
-  pkg_check_modules(GST_APP REQUIRED gstreamer-app-0.10)
-endif()
+# Removed gstreamer-0.10 support
+message(STATUS "gst 1.0")
+pkg_check_modules(GSTREAMER REQUIRED gstreamer-1.0)
+pkg_check_modules(GST_APP REQUIRED gstreamer-app-1.0)
 
 if(USE_ROSBUILD)
   # Use rosbuild
@@ -48,7 +49,7 @@ if(USE_ROSBUILD)
 
 else()
   # Use Catkin
-  find_package(catkin REQUIRED 
+  find_package(catkin REQUIRED
     COMPONENTS roscpp image_transport sensor_msgs nodelet
     camera_calibration_parsers camera_info_manager
     )
@@ -123,8 +124,8 @@ endif()
 # Interim compatibility
 # Remove this in the next distribution release
 configure_file(scripts/gscam_node.in ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/gscam_node)
-file(COPY ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/gscam_node 
+file(COPY ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/gscam_node
   DESTINATION ${EXECUTABLE_OUTPUT_PATH}
   FILE_PERMISSIONS OWNER_READ OWNER_WRITE OWNER_EXECUTE GROUP_READ GROUP_EXECUTE WORLD_READ WORLD_EXECUTE)
 
-
+endif()
diff --git a/README_TI.md b/README_TI.md
new file mode 100644
index 0000000..032627d
--- /dev/null
+++ b/README_TI.md
@@ -0,0 +1,65 @@
+GStreamer Camera Node for ROS 1
+===============================
+This GStreamer based camera ROS node is from [https://github.com/ros-drivers/gscam](https://github.com/ros-drivers/gscam). Some changes are made to customize the original ROS node for the uses with Robotics SDK for TDA4:
+
+* Added GStreamer pipelines that use [the GStreamer plugins optimized for TDA4 devices](https://github.com/TexasInstruments/edgeai-gst-plugins), and added NV12 encoding mode.
+* Added an example `camera_info.yaml` for Logitech webcam C920 and associated LDC look-up-table file (required to use TI TDA4 LDC hardware accelerator).
+* Added launch files (under 'launch' folder) for Logitech webcam (in MJPG mode and YUYV mode), and OV5640 (in YUYV mode).
+* Dependency: following modules are already built and installed in the the Robotics SDK ROS Docker images.
+    * [edgeai-tiovx-modules](https://github.com/TexasInstruments/edgeai-tiovx-modules)
+    * [edgeai-gst-plugins](https://github.com/TexasInstruments/edgeai-gst-plugins)
+
+**Note**: The customization are made only for Robotics SDK for TDA4, and some of examples from the original GIT repository may not work with these changes.
+## Usage
+
+1. Camera Calibration and Rectification Map Generation: See corresponding parts of [mono_capture/README.md](../mono_capture/README.md).
+
+2. Build the ROS node:
+    ```
+    cd $ROS_WS
+    catkin_make --source /opt/robotics_sdk/ros1
+    source devel/setup.bash
+    ```
+
+3. Launch the "gscam" ROS node:
+Before launching the "gscam", please make sure to update `device` in the launch file to point to correct camera device (`/dev/videoX`).
+    For capturing in MJPG (motion JPEG) mode,
+    ```
+    roslaunch gscam v4l_mjpg.launch
+    ```
+    For capturing in YUYV mode,
+    ```
+    roslaunch gscam v4l_yuv.launch
+    roslaunch gscam v4l_ov5640.launch # for OV5640 CSI camera
+    ```
+
+**Note**: The measured framerate for the output topic can be less than the framerate set in the launch file, depending on the light condition of the scenes. This is a normal behavior inherited from `v4l2src` and the ISP settings of, e.g., USB webcam.
+
+## Visualization on Remote Ubuntu PC
+By default, the output topic `raw_image` is published in NV12 color format to make more efficient when the node is integrated with the vision vision CNN processing chain (including `ti_vision_cnn` ROS node) on TDA4. We provide a launch file for visualization on the remote Ubuntu (included in `ti_viz_nodes` ROS package).
+
+In the PC Docker container,
+```
+roslaunch ti_viz_nodes gscam_nv12.launch
+```
+
+## Usage: IMX390 Camera
+Please follow [the hardware setup section of Edge AI documentation](https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-sk-tda4vm/08_02_00/exports/docs/getting_started.html).
+
+To run the gscam node for IMX390 camera,
+```
+# 1080p
+roslaunch gscam v4l_imx390.launch width:=1920 height:=1080
+# 720p
+roslaunch gscam v4l_imx390.launch width:=1280 height:=720
+```
+
+**Note**: The GStreamer pipeline in the launch file also includes the LDC plugin (tiovxldc). Raw resolution is 1936 x 1100. The LDC plugin performs rectification and then cropping to produce 1920 x 1080 images in NV12 format, followed by MSC plugin (tiovxmultiscaler) to resize to the output resolution.
+
+For visualization in the PC Docker container,
+```
+# 1080p
+roslaunch ti_viz_nodes gscam_nv12.launch width:=1920 height:=1080
+# 720p
+roslaunch ti_viz_nodes gscam_nv12.launch width:=1280 height:=720
+```
\ No newline at end of file
diff --git a/config/C920_HD_camera_info.yaml b/config/C920_HD_camera_info.yaml
new file mode 100644
index 0000000..3ce26c2
--- /dev/null
+++ b/config/C920_HD_camera_info.yaml
@@ -0,0 +1,31 @@
+%YAML:1.0
+---
+image_width: 1280
+image_height: 720
+camera_name: camera
+camera_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 1. ]
+distortion_model: plumb_bob
+distortion_coefficients: !!opencv-matrix
+   rows: 1
+   cols: 5
+   dt: d
+   data: [ 7.3934261699576093e-02, -4.1542678753901879e-01,
+       1.4128959036683215e-03, 9.4384360282255390e-04,
+       5.9913436641201279e-01 ]
+rectification_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 1., 0., 0., 0., 1., 0., 0., 0., 1. ]
+projection_matrix: !!opencv-matrix
+   rows: 3
+   cols: 4
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0., 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 0., 1.,
+       0. ]
diff --git a/config/IMX390_HD_camera_info.yaml b/config/IMX390_HD_camera_info.yaml
new file mode 100644
index 0000000..b3ab210
--- /dev/null
+++ b/config/IMX390_HD_camera_info.yaml
@@ -0,0 +1,32 @@
+%YAML:1.0
+---
+# This is just a template. All the coefficients should be from calibration.
+image_width: 1280
+image_height: 720
+camera_name: camera
+camera_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 1. ]
+distortion_model: plumb_bob
+distortion_coefficients: !!opencv-matrix
+   rows: 1
+   cols: 5
+   dt: d
+   data: [ 7.3934261699576093e-02, -4.1542678753901879e-01,
+       1.4128959036683215e-03, 9.4384360282255390e-04,
+       5.9913436641201279e-01 ]
+rectification_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 1., 0., 0., 0., 1., 0., 0., 0., 1. ]
+projection_matrix: !!opencv-matrix
+   rows: 3
+   cols: 4
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0., 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 0., 1.,
+       0. ]
diff --git a/include/gscam/gscam.h b/include/gscam/gscam.h
index e4b4ee2..dc7e2ff 100644
--- a/include/gscam/gscam.h
+++ b/include/gscam/gscam.h
@@ -47,15 +47,21 @@ namespace gscam {
 
     // Camera publisher configuration
     std::string frame_id_;
-    int width_, height_;
+    int width_;
+    int height_;
     std::string image_encoding_;
     std::string camera_name_;
     std::string camera_info_url_;
+    int set_width_;
+    int set_height_;
+    int set_framerate_;
+    std::string app_sink_format_;
 
     // ROS Inteface
     // Calibration between ros::Time and gst timestamps
     double time_offset_;
-    ros::NodeHandle nh_, nh_private_;
+    ros::NodeHandle nh_;
+    ros::NodeHandle nh_private_;
     image_transport::ImageTransport image_transport_;
     camera_info_manager::CameraInfoManager camera_info_manager_;
     image_transport::CameraPublisher camera_pub_;
diff --git a/launch/v4l_imx390.launch b/launch/v4l_imx390.launch
new file mode 100644
index 0000000..6e0143b
--- /dev/null
+++ b/launch/v4l_imx390.launch
@@ -0,0 +1,43 @@
+<launch>
+    <arg name="device"         default="/dev/video18"/>
+    <!-- output resolution: width -->
+    <arg name="width" default="1280"/>
+    <!-- output resolution: height -->
+    <arg name="height" default="720"/>
+    <!-- framerate (integer) -->
+    <arg name="framerate" default="30"/>
+    <!-- image encoding: "yuv420" - publishes in "NV12" (default), "rgb8" -->
+    <arg name="image_encoding" default="yuv420"/>
+    <!-- node name -->
+    <arg name="node_name" default="gscam_node"/>
+    <!-- camera name: also used as namespace for the output topic name -->
+    <arg name="camera_name" default="camera"/>
+    <!-- LDC binary file -->
+    <arg name="ldc_dcc_file" default="/opt/imaging/imx390/dcc_ldc.bin"/>
+    <!-- camera_info URL -->
+    <arg name="camera_info_url" default="package://gscam/config/IMX390_HD_camera_info.yaml"/>
+
+    <!-- GStreamer pipeline specified in gscam_config was tested with IMX390 camera,
+        'edgeai-tiovx-modules' and 'edgeai-gst-plugins' are assumed to be already installed in TDA4 ROS container.
+        Note that the GStreamer pipeline also includes the LDC plugin. Raw resolution is 1936 x 1100,
+        and the LDC plugin (tiovxldc) performs rectification and then cropping to output 1920 x 1080 in NV12.
+        Followed by MSC plugin (tiovxmultiscaler) to resize to the output resolution. -->
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) do-timestamp=true ! video/x-bayer, width=1936, height=1100, format=rggb12 !
+            tiovxisp sink_0::device=/dev/v4l-subdev7 sensor-name=IMX390-UB953_D3 dcc-isp-file=/opt/imaging/imx390/dcc_viss.bin
+            sink_0::dcc-2a-file=/opt/imaging/imx390/dcc_2a.bin format-msb=11 ! video/x-raw, format=NV12 !
+            tiovxldc dcc-file=$(arg ldc_dcc_file) sensor-name=IMX390-UB953_D3 ! video/x-raw, format=NV12, width=1920, height=1080 !
+            tiovxmultiscaler ! video/x-raw, format=NV12, width=$(arg width), height=$(arg height) !
+            tiovxdlcolorconvert target=1 out-pool-size=4"/>
+        <param name="camera_name"     value="$(arg camera_name)"/>
+        <param name="camera_info_url" value="$(arg camera_info_url)"/>
+        <param name="width"           value="$(arg width)"/>
+        <param name="height"          value="$(arg height)"/>
+        <param name="framerate"       value="$(arg framerate)"/>
+        <param name="sync_sink"       value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <param name="image_encoding"  value="$(arg image_encoding)"/>
+    </node>
+
+</launch>
diff --git a/launch/v4l_mjpg.launch b/launch/v4l_mjpg.launch
new file mode 100644
index 0000000..fc4a477
--- /dev/null
+++ b/launch/v4l_mjpg.launch
@@ -0,0 +1,28 @@
+<launch>
+
+    <arg name="device"         default="/dev/video2"/>
+    <!-- framerate (integer) -->
+    <arg name="framerate"      default="30"/>
+    <!-- image encoding: "yuv420" - publishes in "NV12" (default), "rgb8" -->
+    <arg name="image_encoding" default="yuv420"/>
+    <!-- node name -->
+    <arg name="node_name"      default="gscam_node"/>
+    <!-- camera name -->
+    <arg name="camera_name"    default="camera"/>
+
+    <!-- GStreamer pipeline specified in gscam_config was tested with Logitech C920 webcam in MJPG mode,
+        'tiovxcolorconvert' assumes 'edgeai-tiovx-modules' and 'edgeai-gst-plugins' are already installed in TDA4 ROS container -->
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) io-mode=2 do-timestamp=true ! image/jpeg ! jpegdec ! tiovxcolorconvert"/>
+        <param name="camera_name"        value="$(arg camera_name)"/>
+        <param name="camera_info_url"    value="package://gscam/config/C920_HD_camera_info.yaml"/>
+        <param name="width"              value="1280"/>
+        <param name="height"             value="720"/>
+        <param name="framerate"          value="$(arg framerate)"/>
+        <param name="sync_sink"          value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <param name="image_encoding"     value="$(arg image_encoding)"/>
+    </node>
+
+</launch>
diff --git a/launch/v4l_ov5640.launch b/launch/v4l_ov5640.launch
new file mode 100644
index 0000000..4dfde20
--- /dev/null
+++ b/launch/v4l_ov5640.launch
@@ -0,0 +1,29 @@
+<launch>
+    <!-- Please make sure run "bash /opt/edge_ai_apps/init_script.sh" on TDA4 host Linux before launching this for OV5640 -->
+
+    <arg name="device"         default="/dev/video2"/>
+    <!-- framerate (integer) -->
+    <arg name="framerate"      default="30"/>
+    <!-- image encoding: "yuv420" - publishes in "NV12" (default), "rgb8" -->
+    <arg name="image_encoding" default="yuv420"/>
+    <!-- node name -->
+    <arg name="node_name"      default="gscam_node"/>
+    <!-- camera name: also used as namespace for the output topic name -->
+    <arg name="camera_name"    default="camera"/>
+
+    <!-- GStreamer pipeline specified in gscam_config was tested with Logitech C920 webcam in YUYV mode,
+        'tiovxcolorconvert' assumes 'edgeai-tiovx-modules' and 'edgeai-gst-plugins' are already installed in TDA4 ROS container -->
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) do-timestamp=true ! tiovxcolorconvert"/>
+        <param name="camera_name"     value="$(arg camera_name)"/>
+        <param name="camera_info_url" value="package://gscam/config/C920_HD_camera_info.yaml"/>
+        <param name="width"           value="1280"/>
+        <param name="height"          value="720"/>
+        <param name="framerate"       value="$(arg framerate)"/>
+        <param name="sync_sink"       value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <param name="image_encoding"  value="$(arg image_encoding)"/>
+    </node>
+
+</launch>
diff --git a/launch/v4l_yuv.launch b/launch/v4l_yuv.launch
new file mode 100644
index 0000000..9619e4f
--- /dev/null
+++ b/launch/v4l_yuv.launch
@@ -0,0 +1,28 @@
+<launch>
+
+    <arg name="device"         default="/dev/video2"/>
+    <!-- framerate (integer) -->
+    <arg name="framerate"      default="10"/>
+    <!-- image encoding: "yuv420" - publishes in "NV12" (default), "rgb8" -->
+    <arg name="image_encoding" default="yuv420"/>
+    <!-- node name -->
+    <arg name="node_name"      default="gscam_node"/>
+    <!-- camera name: also used as namespace for the output topic name -->
+    <arg name="camera_name"    default="camera"/>
+
+    <!-- GStreamer pipeline specified in gscam_config was tested with Logitech C920 webcam in YUYV mode,
+        'tiovxcolorconvert' assumes 'edgeai-tiovx-modules' and 'edgeai-gst-plugins' are already installed in TDA4 ROS container -->
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) io-mode=0 do-timestamp=true ! tiovxcolorconvert"/>
+        <param name="camera_name"        value="$(arg camera_name)"/>
+        <param name="camera_info_url"    value="package://gscam/config/C920_HD_camera_info.yaml"/>
+        <param name="width"              value="1280"/>
+        <param name="height"             value="720"/>
+        <param name="framerate"          value="$(arg framerate)"/>
+        <param name="sync_sink"          value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <param name="image_encoding"     value="$(arg image_encoding)"/>
+    </node>
+
+</launch>
diff --git a/src/gscam.cpp b/src/gscam.cpp
index d0c6cc9..1d19e26 100644
--- a/src/gscam.cpp
+++ b/src/gscam.cpp
@@ -4,7 +4,6 @@
 #include <sys/ipc.h>
 #include <sys/shm.h>
 
-
 #include <iostream>
 extern "C"{
 #include <gst/gst.h>
@@ -16,7 +15,6 @@ extern "C"{
 #include <image_transport/image_transport.h>
 #include <camera_info_manager/camera_info_manager.h>
 
-
 #include <sensor_msgs/Image.h>
 #include <sensor_msgs/CompressedImage.h>
 #include <sensor_msgs/CameraInfo.h>
@@ -73,21 +71,35 @@ namespace gscam {
     nh_private_.param("sync_sink", sync_sink_, true);
     nh_private_.param("preroll", preroll_, false);
     nh_private_.param("use_gst_timestamps", use_gst_timestamps_, false);
-
     nh_private_.param("reopen_on_eof", reopen_on_eof_, false);
 
     // Get the camera parameters file
     nh_private_.getParam("camera_info_url", camera_info_url_);
     nh_private_.getParam("camera_name", camera_name_);
+    nh_private_.getParam("width", set_width_);
+    nh_private_.getParam("height", set_height_);
+    nh_private_.getParam("framerate", set_framerate_);
 
     // Get the image encoding
-    nh_private_.param("image_encoding", image_encoding_, sensor_msgs::image_encodings::RGB8);
+    nh_private_.param("image_encoding", image_encoding_, std::string("yuv420"));
     if (image_encoding_ != sensor_msgs::image_encodings::RGB8 &&
-        image_encoding_ != sensor_msgs::image_encodings::MONO8 && 
+        // image_encoding_ != sensor_msgs::image_encodings::MONO8 &&
+        // image_encoding_ != "yuv422" &&
+        image_encoding_ != "yuv420" &&
         image_encoding_ != "jpeg") {
       ROS_FATAL_STREAM("Unsupported image encoding: " + image_encoding_);
     }
 
+    // Mapping between image_encoding_ and app_sink_format_
+    // 'tiovxcolorconvert' supports: RGB, NV12
+    if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
+      app_sink_format_ = "RGB";
+    } else if (image_encoding_ == "yuv420") {
+      app_sink_format_ = "NV12";
+    } else if (image_encoding_ == "jpeg") {
+      app_sink_format_ = "";
+    }
+
     camera_info_manager_.setCameraName(camera_name_);
 
     if(camera_info_manager_.validateURL(camera_info_url_)) {
@@ -125,32 +137,24 @@ namespace gscam {
       return false;
     }
 
-    // Create RGB sink
+    // Create app sink
     sink_ = gst_element_factory_make("appsink",NULL);
     GstCaps * caps = gst_app_sink_get_caps(GST_APP_SINK(sink_));
 
-#if (GST_VERSION_MAJOR == 1)
     // http://gstreamer.freedesktop.org/data/doc/gstreamer/head/pwg/html/section-types-definitions.html
-    if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
-        caps = gst_caps_new_simple( "video/x-raw", 
-            "format", G_TYPE_STRING, "RGB",
-            NULL); 
-    } else if (image_encoding_ == sensor_msgs::image_encodings::MONO8) {
-        caps = gst_caps_new_simple( "video/x-raw", 
-            "format", G_TYPE_STRING, "GRAY8",
-            NULL); 
-    } else if (image_encoding_ == "jpeg") {
-        caps = gst_caps_new_simple("image/jpeg", NULL, NULL);
+    if (image_encoding_ == "jpeg") {
+      caps = gst_caps_new_simple("image/jpeg", NULL, NULL);
     }
-#else
-    if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
-        caps = gst_caps_new_simple( "video/x-raw-rgb", NULL,NULL); 
-    } else if (image_encoding_ == sensor_msgs::image_encodings::MONO8) {
-        caps = gst_caps_new_simple("video/x-raw-gray", NULL, NULL);
-    } else if (image_encoding_ == "jpeg") {
-        caps = gst_caps_new_simple("image/jpeg", NULL, NULL);
+    else {
+      ROS_INFO_STREAM("app_sink_format_ = "<<app_sink_format_);
+      caps = gst_caps_new_simple( "video/x-raw",
+          "format", G_TYPE_STRING, app_sink_format_.c_str(),
+          "framerate", GST_TYPE_FRACTION, set_framerate_, 1,
+          "pixel-aspect-ratio", GST_TYPE_FRACTION, 1, 1,
+          "width", G_TYPE_INT, set_width_,
+          "height", G_TYPE_INT, set_height_,
+          NULL);
     }
-#endif
 
     gst_app_sink_set_caps(GST_APP_SINK(sink_), caps);
     gst_caps_unref(caps);
@@ -220,10 +224,10 @@ namespace gscam {
 
     // Create ROS camera interface
     if (image_encoding_ == "jpeg") {
-        jpeg_pub_ = nh_.advertise<sensor_msgs::CompressedImage>("camera/image_raw/compressed",1);
-        cinfo_pub_ = nh_.advertise<sensor_msgs::CameraInfo>("camera/camera_info",1);
+        jpeg_pub_ = nh_.advertise<sensor_msgs::CompressedImage>(camera_name_ + "/image_raw/compressed",1);
+        cinfo_pub_ = nh_.advertise<sensor_msgs::CameraInfo>(camera_name_ + "/camera_info",1);
     } else {
-        camera_pub_ = image_transport_.advertiseCamera("camera/image_raw", 1);
+        camera_pub_ = image_transport_.advertiseCamera(camera_name_ + "/image_raw", 1);
     }
 
     return true;
@@ -262,13 +266,12 @@ namespace gscam {
     }
     ROS_INFO("Started stream.");
 
-    // Poll the data as fast a spossible
-    while(ros::ok()) 
+    // Poll the data as fast as possible
+    while(ros::ok())
     {
       // This should block until a new frame is awake, this way, we'll run at the
       // actual capture framerate of the device.
       // ROS_DEBUG("Getting data...");
-#if (GST_VERSION_MAJOR == 1)
       GstSample* sample = gst_app_sink_pull_sample(GST_APP_SINK(sink_));
       if(!sample) {
         ROS_ERROR("Could not get gstreamer sample.");
@@ -281,26 +284,10 @@ namespace gscam {
       gst_memory_map(memory, &info, GST_MAP_READ);
       gsize &buf_size = info.size;
       guint8* &buf_data = info.data;
-#else
-      GstBuffer* buf = gst_app_sink_pull_buffer(GST_APP_SINK(sink_));
-      guint &buf_size = buf->size;
-      guint8* &buf_data = buf->data;
-#endif
       GstClockTime bt = gst_element_get_base_time(pipeline_);
       // ROS_INFO("New buffer: timestamp %.6f %lu %lu %.3f",
       //         GST_TIME_AS_USECONDS(buf->timestamp+bt)/1e6+time_offset_, buf->timestamp, bt, time_offset_);
 
-
-#if 0
-      GstFormat fmt = GST_FORMAT_TIME;
-      gint64 current = -1;
-
-       Query the current position of the stream
-      if (gst_element_query_position(pipeline_, &fmt, &current)) {
-          ROS_INFO_STREAM("Position "<<current);
-      }
-#endif
-
       // Stop on end of stream
       if (!buf) {
         ROS_INFO("Stream ended.");
@@ -311,11 +298,7 @@ namespace gscam {
 
       // Get the image width and height
       GstPad* pad = gst_element_get_static_pad(sink_, "sink");
-#if (GST_VERSION_MAJOR == 1)
       const GstCaps *caps = gst_pad_get_current_caps(pad);
-#else
-      const GstCaps *caps = gst_pad_get_negotiated_caps(pad);
-#endif
       GstStructure *structure = gst_caps_get_structure(caps,0);
       gst_structure_get_int(structure,"width",&width_);
       gst_structure_get_int(structure,"height",&height_);
@@ -325,11 +308,7 @@ namespace gscam {
       sensor_msgs::CameraInfoPtr cinfo;
       cinfo.reset(new sensor_msgs::CameraInfo(cur_cinfo));
       if (use_gst_timestamps_) {
-#if (GST_VERSION_MAJOR == 1)
           cinfo->header.stamp = ros::Time(GST_TIME_AS_USECONDS(buf->pts+bt)/1e6+time_offset_);
-#else
-          cinfo->header.stamp = ros::Time(GST_TIME_AS_USECONDS(buf->timestamp+bt)/1e6+time_offset_);
-#endif
       } else {
           cinfo->header.stamp = ros::Time::now();
       }
@@ -346,14 +325,19 @@ namespace gscam {
           cinfo_pub_.publish(cinfo);
       } else {
           // Complain if the returned buffer is smaller than we expect
-          const unsigned int expected_frame_size =
-              image_encoding_ == sensor_msgs::image_encodings::RGB8
-              ? width_ * height_ * 3
-              : width_ * height_;
-
-          if (buf_size < expected_frame_size) {
-              ROS_WARN_STREAM( "GStreamer image buffer underflow: Expected frame to be "
-                      << expected_frame_size << " bytes but got only "
+          unsigned int expected_frame_size;
+          if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
+              expected_frame_size = width_ * height_ * 3;
+          }
+          else if (image_encoding_ == "yuv420") {
+              expected_frame_size = width_ * height_ * 1.5;
+          }
+          else {
+              expected_frame_size = width_ * height_;
+          }
+          if (buf_size != expected_frame_size) {
+              ROS_WARN_STREAM( "GStreamer image buffer underflow or overflow: Expected frame to be "
+                      << expected_frame_size << " bytes but got "
                       << (buf_size) << " bytes. (make sure frames are correctly encoded)");
           }
 
@@ -374,12 +358,12 @@ namespace gscam {
           // we can free the buffer allocated by gstreamer
           if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
               img->step = width_ * 3;
+          } else if (image_encoding_ == "yuv420") { // NV12
+              img->step = width_;
           } else {
               img->step = width_;
           }
-          std::copy(
-                  buf_data,
-                  (buf_data)+(buf_size),
+          std::copy(buf_data, (buf_data)+(buf_size),
                   img->data.begin());
 
           // Publish the image/info
@@ -388,11 +372,11 @@ namespace gscam {
 
       // Release the buffer
       if(buf) {
-#if (GST_VERSION_MAJOR == 1)
         gst_memory_unmap(memory, &info);
         gst_memory_unref(memory);
-#endif
-        gst_buffer_unref(buf);
+        // https://github.com/clydemcqueen/gscam2/issues/9
+        // gst_buffer_unref(buf);
+        gst_sample_unref(sample);
       }
 
       ros::spinOnce();
