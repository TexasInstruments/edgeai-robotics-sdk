diff --git a/CMakeLists.txt b/CMakeLists.txt
index 98166b7..70531c3 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -2,22 +2,23 @@ cmake_minimum_required(VERSION 2.8.3)
 
 project(gscam)
 
+if (${CMAKE_SYSTEM_PROCESSOR} STREQUAL "x86_64")
+    set(BUILD_CORE_NODES          OFF)
+elseif (${CMAKE_SYSTEM_PROCESSOR} STREQUAL "aarch64")
+    set(BUILD_CORE_NODES          ON CACHE BOOL "Build core nodes")
+else()
+    message(FATAL_ERROR "Unknown processor:" ${CMAKE_SYSTEM_PROCESSOR})
+endif()
+
+if(${BUILD_CORE_NODES})
+
 # System Dependencies
 find_package(PkgConfig)
 
-pkg_check_modules(GSTREAMER QUIET gstreamer-0.10)
-if(NOT GSTREAMER_FOUND)
-  set(GSTREAMER_VERSION_1_x TRUE)
-endif()
-if(GSTREAMER_VERSION_1_x)
-  message(STATUS "gst 1.0")
-  pkg_check_modules(GSTREAMER REQUIRED gstreamer-1.0)
-  pkg_check_modules(GST_APP REQUIRED gstreamer-app-1.0)
-else()
-  message(STATUS "gst 0.1")
-  pkg_check_modules(GSTREAMER REQUIRED gstreamer-0.10)
-  pkg_check_modules(GST_APP REQUIRED gstreamer-app-0.10)
-endif()
+# Removed gstreamer-0.10 support
+message(STATUS "gst 1.0")
+pkg_check_modules(GSTREAMER REQUIRED gstreamer-1.0)
+pkg_check_modules(GST_APP REQUIRED gstreamer-app-1.0)
 
 if(USE_ROSBUILD)
   # Use rosbuild
@@ -48,7 +49,7 @@ if(USE_ROSBUILD)
 
 else()
   # Use Catkin
-  find_package(catkin REQUIRED 
+  find_package(catkin REQUIRED
     COMPONENTS roscpp image_transport sensor_msgs nodelet
     camera_calibration_parsers camera_info_manager
     )
@@ -123,8 +124,8 @@ endif()
 # Interim compatibility
 # Remove this in the next distribution release
 configure_file(scripts/gscam_node.in ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/gscam_node)
-file(COPY ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/gscam_node 
+file(COPY ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/gscam_node
   DESTINATION ${EXECUTABLE_OUTPUT_PATH}
   FILE_PERMISSIONS OWNER_READ OWNER_WRITE OWNER_EXECUTE GROUP_READ GROUP_EXECUTE WORLD_READ WORLD_EXECUTE)
 
-
+endif()
diff --git a/README_TI.md b/README_TI.md
new file mode 100644
index 0000000..c1da33c
--- /dev/null
+++ b/README_TI.md
@@ -0,0 +1,136 @@
+GStreamer Camera Node for ROS 1
+===============================
+This GStreamer based camera ROS node is from [https://github.com/ros-drivers/gscam](https://github.com/ros-drivers/gscam). Following changes are made to customize for the use cases in the Robotics SDK:
+
+* Added GStreamer pipelines that use [the GStreamer plugins optimized for TI Processors](https://github.com/TexasInstruments/edgeai-gst-plugins), and added NV12 encoding mode for the output.
+* Added an example `camera_info.yaml` for Logitech webcam C920 and associated LDC look-up-table file (required to use the LDC hardware accelerator).
+* Added launch files (under 'launch' folder) for Logitech webcam (in MJPG mode and YUYV mode) and OV5640 (in YUYV mode) CSI camera with GStreamer pipelines using the plugins optimized on TI devices.
+* Added launch files for IMX390 FPD-Link cameras with GStreamer pipelines using the plugins optimized on TI devices.
+* Dependency: following modules are already built and installed in the the Robotics SDK ROS Docker images.
+    * [edgeai-tiovx-modules](https://github.com/TexasInstruments/edgeai-tiovx-modules)
+    * [edgeai-gst-plugins](https://github.com/TexasInstruments/edgeai-gst-plugins)
+
+```{note}
+The customization are made only for the Robotics SDK. It was not verified that all examples from the original GIT repository still work with these changes.
+```
+
+## Usage: USB Camera
+
+### Running gscam on the target
+
+1. Camera Calibration and Rectification Map Generation: See corresponding parts of [mono_capture/README.md](../mono_capture/README.md).
+
+2. Build the ROS node:
+    ```
+    cd $ROS_WS
+    catkin_make --source /opt/robotics_sdk/ros1
+    source devel/setup.bash
+    ```
+
+3. Launch the "gscam" ROS node:
+Before launching the "gscam", please make sure to update `device` in the launch file to point to correct camera device (`/dev/videoX`).
+    For capturing in MJPG (motion JPEG) mode,
+    ```
+    roslaunch gscam v4l_mjpg.launch
+    ```
+    For capturing in YUYV mode,
+    ```
+    roslaunch gscam v4l_yuv.launch
+    roslaunch gscam v4l_ov5640.launch # for OV5640 CSI camera
+    ```
+
+```{note}
+The measured framerate for the output topic can be less than the framerate set in the launch file, depending on the light condition of the scenes. This is a normal behavior inherited from `v4l2src` and the default ISP settings of the USB webcam.
+```
+
+### Visualization on remote PC
+
+By default, the output topic `raw_image` is published in NV12 color format to make more efficient when the node is integrated with the vision vision CNN processing chain (including `ti_vision_cnn` ROS node) on the target. We provide a launch file for visualization on the remote Ubuntu (included in `ti_viz_nodes` ROS package).
+
+In the PC Docker container,
+```
+roslaunch ti_viz_nodes gscam_nv12.launch
+```
+
+## Usage: IMX219 Camera
+
+```{only} tag_j7x
+Please follow [the hardware setup section of Edge AI documentation](https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-edgeai/TDA4VM/latest/exports/docs/devices/TDA4VM/linux/getting_started.html#rpiv2-imx219-raw-sensor).
+```
+```{only} tag_am62a
+Please follow [the hardware setup section of Edge AI documentation](https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-edgeai/AM62AX/latest/exports/docs/devices/AM62AX/linux/getting_started.html#rpiv2-imx219-raw-sensor).
+```
+
+You can check the device ID and subdev ID for the IMX219 CSI camera attached to the hardware setup by running `/opt/edgeai-gst-apps/scripts/setup_cameras.sh` on the target host Linux. Accordingly please update the launch files below, or it's also possible to pass as launch arguments.
+
+### Running gscam with resizing
+To publish the captured images from the IMX219 camera,
+```
+roslaunch gscam v4l_imx219.launch device_id:=X subdev_id:=Y
+```
+
+```{note}
+The GStreamer pipeline in `v4l_imx219.launch` includes the ISP plugin (tiovxisp) followed by the image scaler plugin (tiovxmultiscaler) to resize the images to the output resolution. The output images are published in NV12 format.
+```
+
+### Visualization on remote PC
+
+For visualization, run the following in the PC Docker container,
+```
+roslaunch ti_viz_nodes gscam_nv12.launch width:=1280 height:=720
+```
+
+## Usage: IMX390 Camera
+
+```{only} tag_j7x
+Please follow [the hardware setup section of Edge AI documentation](https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-edgeai/TDA4VM/latest/exports/docs/devices/TDA4VM/linux/getting_started.html#imx390-raw-sensor).
+```
+```{only} tag_am62a
+Please follow [the hardware setup section of Edge AI documentation](https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-edgeai/AM62AX/latest/exports/docs/devices/AM62AX/linux/getting_started.html#imx390-raw-sensor).
+```
+
+### Running gscam for raw image capture
+
+You can check the device ID and subdev ID for the IMX390 camera attached to the hardware setup by running `/opt/edgeai-gst-apps/scripts/setup_cameras.sh` on the target host Linux. Accordingly please update the launch files below, or it's also possible to pass as launch arguments.
+
+To publish raw images in the native resolution (1936 x 1096),
+```
+roslaunch gscam v4l_imx390_raw.launch
+```
+### Running gscam with rectification and resizing
+
+We also provide a launch file that includes rectification and resizing in the GStreamer pipeline.
+
+````{note}
+`v4l_imx390.launch` has `tiovxldc` in the GStreamer pipeline and
+`tiovxldc` requires `lut-file`. The LUT file is specific to the camera.
+As an example, we provide camera calibration data for a fisheye IMX390 camera
+is provided in the form of camera_info YAML file. To generate the LUT files,
+please run the following in the Robotics SDK Docker container on the target:
+```
+$ bash /opt/robotics_sdk/tools/mono_camera/imx390_ldc.sh
+```
+````
+
+```
+# 1080p
+roslaunch gscam v4l_imx390.launch width:=1920 height:=1080
+# 720p
+roslaunch gscam v4l_imx390.launch width:=1280 height:=720
+```
+
+```{note}
+The GStreamer pipeline in `v4l_imx390.launch` also includes the LDC plugin (tiovxldc). Raw resolution is 1936 x 1096. The LDC plugin performs rectification and then cropping to produce 1920 x 1080 images in NV12 format, followed by MSC plugin (tiovxmultiscaler) to resize the images to the output resolution.
+```
+
+### Visualization on remote PC
+
+For visualization, run the following in the PC Docker container,
+```
+# native resolution (1936 x 1096)
+roslaunch ti_viz_nodes gscam_nv12.launch width:=1936 height:=1096
+# 1080p
+roslaunch ti_viz_nodes gscam_nv12.launch width:=1920 height:=1080
+# 720p
+roslaunch ti_viz_nodes gscam_nv12.launch width:=1280 height:=720
+```
diff --git a/config/C920_HD_camera_info.yaml b/config/C920_HD_camera_info.yaml
new file mode 100644
index 0000000..3ce26c2
--- /dev/null
+++ b/config/C920_HD_camera_info.yaml
@@ -0,0 +1,31 @@
+%YAML:1.0
+---
+image_width: 1280
+image_height: 720
+camera_name: camera
+camera_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 1. ]
+distortion_model: plumb_bob
+distortion_coefficients: !!opencv-matrix
+   rows: 1
+   cols: 5
+   dt: d
+   data: [ 7.3934261699576093e-02, -4.1542678753901879e-01,
+       1.4128959036683215e-03, 9.4384360282255390e-04,
+       5.9913436641201279e-01 ]
+rectification_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 1., 0., 0., 0., 1., 0., 0., 0., 1. ]
+projection_matrix: !!opencv-matrix
+   rows: 3
+   cols: 4
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0., 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 0., 1.,
+       0. ]
diff --git a/config/IMX219_HD_camera_info.yaml b/config/IMX219_HD_camera_info.yaml
new file mode 100644
index 0000000..b3ab210
--- /dev/null
+++ b/config/IMX219_HD_camera_info.yaml
@@ -0,0 +1,32 @@
+%YAML:1.0
+---
+# This is just a template. All the coefficients should be from calibration.
+image_width: 1280
+image_height: 720
+camera_name: camera
+camera_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 1. ]
+distortion_model: plumb_bob
+distortion_coefficients: !!opencv-matrix
+   rows: 1
+   cols: 5
+   dt: d
+   data: [ 7.3934261699576093e-02, -4.1542678753901879e-01,
+       1.4128959036683215e-03, 9.4384360282255390e-04,
+       5.9913436641201279e-01 ]
+rectification_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 1., 0., 0., 0., 1., 0., 0., 0., 1. ]
+projection_matrix: !!opencv-matrix
+   rows: 3
+   cols: 4
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0., 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 0., 1.,
+       0. ]
diff --git a/config/IMX390_HD_camera_info.yaml b/config/IMX390_HD_camera_info.yaml
new file mode 100644
index 0000000..b3ab210
--- /dev/null
+++ b/config/IMX390_HD_camera_info.yaml
@@ -0,0 +1,32 @@
+%YAML:1.0
+---
+# This is just a template. All the coefficients should be from calibration.
+image_width: 1280
+image_height: 720
+camera_name: camera
+camera_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 1. ]
+distortion_model: plumb_bob
+distortion_coefficients: !!opencv-matrix
+   rows: 1
+   cols: 5
+   dt: d
+   data: [ 7.3934261699576093e-02, -4.1542678753901879e-01,
+       1.4128959036683215e-03, 9.4384360282255390e-04,
+       5.9913436641201279e-01 ]
+rectification_matrix: !!opencv-matrix
+   rows: 3
+   cols: 3
+   dt: d
+   data: [ 1., 0., 0., 0., 1., 0., 0., 0., 1. ]
+projection_matrix: !!opencv-matrix
+   rows: 3
+   cols: 4
+   dt: d
+   data: [ 9.3797299601201667e+02, 0., 6.4110167315102080e+02, 0., 0.,
+       9.3981016471195335e+02, 3.8512990806142415e+02, 0., 0., 0., 1.,
+       0. ]
diff --git a/include/gscam/gscam.h b/include/gscam/gscam.h
index e4b4ee2..dc7e2ff 100644
--- a/include/gscam/gscam.h
+++ b/include/gscam/gscam.h
@@ -47,15 +47,21 @@ namespace gscam {
 
     // Camera publisher configuration
     std::string frame_id_;
-    int width_, height_;
+    int width_;
+    int height_;
     std::string image_encoding_;
     std::string camera_name_;
     std::string camera_info_url_;
+    int set_width_;
+    int set_height_;
+    int set_framerate_;
+    std::string app_sink_format_;
 
     // ROS Inteface
     // Calibration between ros::Time and gst timestamps
     double time_offset_;
-    ros::NodeHandle nh_, nh_private_;
+    ros::NodeHandle nh_;
+    ros::NodeHandle nh_private_;
     image_transport::ImageTransport image_transport_;
     camera_info_manager::CameraInfoManager camera_info_manager_;
     image_transport::CameraPublisher camera_pub_;
diff --git a/launch/v4l_imx219.launch b/launch/v4l_imx219.launch
new file mode 100644
index 0000000..6ce8cb1
--- /dev/null
+++ b/launch/v4l_imx219.launch
@@ -0,0 +1,52 @@
+<launch>
+    <!-- You can check the device ID and subdev ID for the IMX219 camera (RPi v2
+    attached by running /opt/edgeai-gst-apps/scripts/setup_cameras.sh on the target
+    host Linux. Accordingly please update the parameters or pass as launch arguments. -->
+    <arg name="device" default="/dev/video2"/>
+    <arg name="subdev" default="/dev/v4l-subdev2"/>
+    <!-- output resolution: width and height -->
+    <arg name="width" default="1280"/>
+    <arg name="height" default="720"/>
+    <!-- framerate (integer): 30 (default) FPS -->
+    <!-- If 30 FPS has issue, try a pipleline without videorate -->
+    <arg name="framerate" default="30"/>
+    <!-- node name -->
+    <arg name="node_name" default="gscam_node"/>
+    <!-- camera name: also used as namespace for the output topic name -->
+    <arg name="camera_name" default="camera"/>
+    <!-- DCC VISS binary file -->
+    <arg name="dcc_isp_file" default="/opt/imaging/imx219/dcc_viss.bin"/>
+    <!-- DCC 2A binary file -->
+    <arg name="dcc_2a_file" default="/opt/imaging/imx219/dcc_2a.bin"/>
+    <!-- edgeai-gst-plugins sensor name -->
+    <arg name="sensor_name" default="SENSOR_SONY_IMX219_RPI"/>
+    <!-- LDC binary file -->
+    <!-- camera_info URL: replace with camera_info from camera calibration -->
+    <!-- package://ros_package_name/config/camera_info.yaml -->
+    <!-- file:///full/path/to/local/file.yaml -->
+    <arg name="camera_info_url" default="package://gscam/config/IMX219_HD_camera_info.yaml"/>
+
+    <!-- GStreamer pipeline specified in gscam_config was tested with IMX219 camera,
+        'edgeai-tiovx-modules' and 'edgeai-gst-plugins' are assumed to be already
+        installed in target ROS container.-->
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) io-mode=5 do-timestamp=true !
+            video/x-bayer, width=1920, height=1080, format=rggb !
+            tiovxisp sink_0::device=$(arg subdev) dcc-isp-file=$(arg dcc_isp_file)
+            sink_0::dcc-2a-file=$(arg dcc_2a_file) format-msb=7 sensor-name=$(arg sensor_name) !
+            video/x-raw, format=NV12 !
+            tiovxmultiscaler ! video/x-raw, width=$(arg width), height=$(arg height) !
+            tiovxdlcolorconvert target=1 out-pool-size=4"/>
+        <param name="camera_name"     value="$(arg camera_name)"/>
+        <param name="camera_info_url" value="$(arg camera_info_url)"/>
+        <param name="width"           value="$(arg width)"/>
+        <param name="height"          value="$(arg height)"/>
+        <param name="framerate"       value="$(arg framerate)"/>
+        <param name="sync_sink"       value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <!-- image encoding: "yuv420" - publish in "NV12" -->
+        <param name="image_encoding"  value="yuv420"/>
+    </node>
+
+</launch>
diff --git a/launch/v4l_imx390.launch b/launch/v4l_imx390.launch
new file mode 100644
index 0000000..d4eda93
--- /dev/null
+++ b/launch/v4l_imx390.launch
@@ -0,0 +1,61 @@
+<launch>
+
+    <!-- NOTE: v4l_imx390.launch has tiovxldc in the GStreamer pipeline and
+    tiovxldc requires lut-file. The LUT file is specific to the camera.
+    As an example, we provide camera calibration data for a fisheye IMX390 camera
+    is provided in the form of camera_info YAML file. To generate the LUT files,
+    please run the following in the Robotics SDK Docker container on the target target:
+    $ bash /opt/robotics_sdk/tools/mono_camera/imx390_ldc.sh -->
+
+    <!-- You can check the device ID and subdev ID for the IMX390 camera attached
+    by running /opt/edgeai-gst-apps/scripts/setup_cameras.sh on the target host Linux.
+    Accordingly please update the parameters or pass as launch argument. -->
+    <arg name="device" default="/dev/video18"/>
+    <arg name="subdev" default="/dev/v4l-subdev7"/>
+    <!-- output resolution: width and height -->
+    <arg name="width" default="1280"/>
+    <arg name="height" default="720"/>
+    <!-- framerate (integer): 30 (default) FPS -->
+    <!-- If 30 FPS has issue, try a pipleline without videorate -->
+    <arg name="framerate" default="30"/>
+    <!-- node name -->
+    <arg name="node_name" default="gscam_node"/>
+    <!-- camera name: also used as namespace for the output topic name -->
+    <arg name="camera_name" default="camera"/>
+    <!-- edgeai-gst-plugins sensor name -->
+    <arg name="sensor_name" default="SENSOR_SONY_IMX390_UB953_D3"/>
+    <!-- DCC VISS binary file -->
+    <arg name="dcc_isp_file" default="/opt/imaging/imx390/dcc_viss.bin"/>
+    <!-- DCC 2A binary file -->
+    <arg name="dcc_2a_file" default="/opt/imaging/imx390/dcc_2a.bin"/>
+    <!-- LDC binary file -->
+    <!-- camera_info URL: replace with camera_info from camera calibration -->
+    <!-- package://ros_package_name/config/camera_info.yaml -->
+    <!-- file:///full/path/to/local/file.yaml -->
+    <!-- <arg name="camera_info_url" default="package://gscam/config/IMX390_HD_camera_info.yaml"/> -->
+
+    <!-- GStreamer pipeline specified in gscam_config was tested with IMX390 camera,
+        'edgeai-tiovx-modules' and 'edgeai-gst-plugins' are assumed to be already installed in target ROS container.
+        Note: GStreamer pipeline also includes the LDC plugin. Raw resolution is 1936 x 1096,
+        and the LDC plugin (tiovxldc) performs rectification and resizing to have output resolution in NV12.
+        Note: /dev/v4l-subdev ID can change, depending on the device attached, and at reboot. -->
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) do-timestamp=true ! videorate ! video/x-bayer, framerate=$(arg framerate)/1, width=1936, height=1096, format=rggb12 !
+            tiovxisp sink_0::device=$(arg subdev) sensor-name=$(arg sensor_name) dcc-isp-file=$(arg dcc_isp_file)
+            sink_0::dcc-2a-file=$(arg dcc_2a_file) format-msb=11 ! video/x-raw, format=NV12 !
+            tiovxldc sensor-name=$(arg sensor_name) lut-file=/opt/imaging/imx390/imx390_35244_equidistant_$(arg width)x$(arg height)_LUT.bin ldc-ds-factor=2 ldc-table-width=$(arg width) ldc-table-height=$(arg height) out-block-height=32 out-block-width=32 !
+            video/x-raw, format=NV12, width=$(arg width), height=$(arg height) !
+            tiovxdlcolorconvert target=1 out-pool-size=4"/>
+        <param name="camera_name"     value="$(arg camera_name)"/>
+        <param name="camera_info_url" value="file:///opt/imaging/imx390/imx390_35244_equidistant_$(arg width)x$(arg height)_rect.yaml"/>
+        <param name="width"           value="$(arg width)"/>
+        <param name="height"          value="$(arg height)"/>
+        <param name="framerate"       value="$(arg framerate)"/>
+        <param name="sync_sink"       value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <!-- image encoding: "yuv420" - publish in "NV12" -->
+        <param name="image_encoding"  value="yuv420"/>
+    </node>
+
+</launch>
diff --git a/launch/v4l_imx390_raw.launch b/launch/v4l_imx390_raw.launch
new file mode 100644
index 0000000..da25647
--- /dev/null
+++ b/launch/v4l_imx390_raw.launch
@@ -0,0 +1,44 @@
+<launch>
+    <!-- You can check the device ID and subdev ID for the IMX390 camera attached
+    by running /opt/edge_ai_apps/scripts/setup_cameras.sh.
+    Accordingly please update the parameters pass as arguments -->
+    <arg name="device" default="/dev/video18"/>
+    <arg name="subdev" default="/dev/v4l-subdev7"/>
+    <!-- framerate (integer): inactive, 30 FPS (default, max) -->
+    <!-- Can be enabled by e.g., adding videorate before tiovxdlcolorconvert, but it creases A72 loading -->
+    <arg name="framerate" default="30"/>
+    <!-- node name -->
+    <arg name="node_name" default="gscam_node"/>
+    <!-- camera name: also used as namespace for the output topic name -->
+    <arg name="camera_name" default="camera"/>
+    <!-- edgeai-gst-plugins sensor name -->
+    <arg name="sensor_name" default="SENSOR_SONY_IMX390_UB953_D3"/>
+    <!-- DCC VISS binary file -->
+    <arg name="dcc_isp_file" default="/opt/imaging/imx390/dcc_viss.bin"/>
+    <!-- DCC 2A binary file -->
+    <arg name="dcc_2a_file" default="/opt/imaging/imx390/dcc_2a.bin"/>
+    <!-- camera_info URL: replace with camera_info from camera calibration -->
+    <arg name="camera_info_url" default="/opt/robotics_sdk/tools/mono_camera/imx390_35244_equidistant_camera_info.yaml"/>
+
+    <!-- GStreamer pipeline specified in gscam_config was tested with IMX390 camera,
+        'edgeai-tiovx-modules' and 'edgeai-gst-plugins' are assumed to be already installed in TDA4 ROS container.
+        Raw resolution is 1936 x 1096 at 30 FPS.
+        Note: /dev/v4l-subdev ID can change, depending on the device attached, and at reboot. -->
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) do-timestamp=true ! video/x-bayer, width=1936, height=1096, format=rggb12 !
+            tiovxisp sink_0::device=$(arg subdev) sensor-name=$(arg sensor_name) dcc-isp-file=$(arg dcc_isp_file)
+            sink_0::dcc-2a-file=$(arg dcc_2a_file) format-msb=11 ! video/x-raw, format=NV12 !
+            tiovxdlcolorconvert target=1 out-pool-size=4 "/>
+        <param name="camera_name"     value="$(arg camera_name)"/>
+        <param name="camera_info_url" value="$(arg camera_info_url)"/>
+        <param name="width"           value="1936"/>
+        <param name="height"          value="1096"/>
+        <param name="framerate"       value="$(arg framerate)"/>
+        <param name="sync_sink"       value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <!-- image encoding: "yuv420" - publish in NV12 -->
+        <param name="image_encoding"  value="yuv420"/>
+    </node>
+
+</launch>
diff --git a/launch/v4l_mjpg.launch b/launch/v4l_mjpg.launch
new file mode 100644
index 0000000..0ab2e9b
--- /dev/null
+++ b/launch/v4l_mjpg.launch
@@ -0,0 +1,29 @@
+<launch>
+    <!-- GStreamer pipeline specified in gscam_config was tested with Logitech C920 webcam in MJPG mode,
+        'tiovxdlcolorconvert' assumes 'edgeai-tiovx-modules' and 'edgeai-gst-plugins'
+        are already installed in target ROS container. -->
+
+    <arg name="device"         default="/dev/video2"/>
+    <!-- framerate (integer) -->
+    <arg name="framerate"      default="30"/>
+    <!-- image encoding: "yuv420" - publishes in "NV12" (default), "rgb8" -->
+    <arg name="image_encoding" default="yuv420"/>
+    <!-- node name -->
+    <arg name="node_name"      default="gscam_node"/>
+    <!-- camera name -->
+    <arg name="camera_name"    default="camera"/>
+
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) io-mode=2 do-timestamp=true ! image/jpeg ! jpegdec ! tiovxdlcolorconvert "/>
+        <param name="camera_name"        value="$(arg camera_name)"/>
+        <param name="camera_info_url"    value="package://gscam/config/C920_HD_camera_info.yaml"/>
+        <param name="width"              value="1280"/>
+        <param name="height"             value="720"/>
+        <param name="framerate"          value="$(arg framerate)"/>
+        <param name="sync_sink"          value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <param name="image_encoding"     value="$(arg image_encoding)"/>
+    </node>
+
+</launch>
diff --git a/launch/v4l_ov5640.launch b/launch/v4l_ov5640.launch
new file mode 100644
index 0000000..f37b060
--- /dev/null
+++ b/launch/v4l_ov5640.launch
@@ -0,0 +1,32 @@
+<launch>
+    <!-- Please make sure run "bash /opt/edgeai-gst-apps/init_script.sh" on target host Linux before launching this for OV5640 -->
+
+    <!-- GStreamer pipeline specified in gscam_config was tested with OV5640 CSI camera in YUYV mode,
+        'tiovxdlcolorconvert' assumes 'edgeai-tiovx-modules' and 'edgeai-gst-plugins'
+        are already installed in target ROS container. -->
+
+
+    <arg name="device"         default="/dev/video2"/>
+    <!-- framerate (integer) -->
+    <arg name="framerate"      default="30"/>
+    <!-- image encoding: "yuv420" - publishes in "NV12" (default), "rgb8" -->
+    <arg name="image_encoding" default="yuv420"/>
+    <!-- node name -->
+    <arg name="node_name"      default="gscam_node"/>
+    <!-- camera name: also used as namespace for the output topic name -->
+    <arg name="camera_name"    default="camera"/>
+
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) do-timestamp=true ! tiovxdlcolorconvert"/>
+        <param name="camera_name"     value="$(arg camera_name)"/>
+        <param name="camera_info_url" value="package://gscam/config/C920_HD_camera_info.yaml"/>
+        <param name="width"           value="1280"/>
+        <param name="height"          value="720"/>
+        <param name="framerate"       value="$(arg framerate)"/>
+        <param name="sync_sink"       value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <param name="image_encoding"  value="$(arg image_encoding)"/>
+    </node>
+
+</launch>
diff --git a/launch/v4l_yuv.launch b/launch/v4l_yuv.launch
new file mode 100644
index 0000000..a7ab999
--- /dev/null
+++ b/launch/v4l_yuv.launch
@@ -0,0 +1,29 @@
+<launch>
+    <!-- GStreamer pipeline specified in gscam_config was tested with Logitech C920 webcam in YUYV mode,
+        'tiovxdlcolorconvert' assumes 'edgeai-tiovx-modules' and 'edgeai-gst-plugins'
+        are already installed in target ROS container. -->
+
+    <arg name="device"         default="/dev/video2"/>
+    <!-- framerate (integer) -->
+    <arg name="framerate"      default="10"/>
+    <!-- image encoding: "yuv420" - publishes in "NV12" (default), "rgb8" -->
+    <arg name="image_encoding" default="yuv420"/>
+    <!-- node name -->
+    <arg name="node_name"      default="gscam_node"/>
+    <!-- camera name: also used as namespace for the output topic name -->
+    <arg name="camera_name"    default="camera"/>
+
+    <node pkg="gscam" name="$(arg node_name)" type="gscam" output="screen">
+        <param name="gscam_config"
+            value="v4l2src device=$(arg device) io-mode=0 do-timestamp=true ! tiovxdlcolorconvert"/>
+        <param name="camera_name"        value="$(arg camera_name)"/>
+        <param name="camera_info_url"    value="package://gscam/config/C920_HD_camera_info.yaml"/>
+        <param name="width"              value="1280"/>
+        <param name="height"             value="720"/>
+        <param name="framerate"          value="$(arg framerate)"/>
+        <param name="sync_sink"          value="false"/>
+        <param name="use_gst_timestamps" value="false"/>
+        <param name="image_encoding"     value="$(arg image_encoding)"/>
+    </node>
+
+</launch>
diff --git a/src/gscam.cpp b/src/gscam.cpp
index d0c6cc9..1d19e26 100644
--- a/src/gscam.cpp
+++ b/src/gscam.cpp
@@ -4,7 +4,6 @@
 #include <sys/ipc.h>
 #include <sys/shm.h>
 
-
 #include <iostream>
 extern "C"{
 #include <gst/gst.h>
@@ -16,7 +15,6 @@ extern "C"{
 #include <image_transport/image_transport.h>
 #include <camera_info_manager/camera_info_manager.h>
 
-
 #include <sensor_msgs/Image.h>
 #include <sensor_msgs/CompressedImage.h>
 #include <sensor_msgs/CameraInfo.h>
@@ -73,21 +71,35 @@ namespace gscam {
     nh_private_.param("sync_sink", sync_sink_, true);
     nh_private_.param("preroll", preroll_, false);
     nh_private_.param("use_gst_timestamps", use_gst_timestamps_, false);
-
     nh_private_.param("reopen_on_eof", reopen_on_eof_, false);
 
     // Get the camera parameters file
     nh_private_.getParam("camera_info_url", camera_info_url_);
     nh_private_.getParam("camera_name", camera_name_);
+    nh_private_.getParam("width", set_width_);
+    nh_private_.getParam("height", set_height_);
+    nh_private_.getParam("framerate", set_framerate_);
 
     // Get the image encoding
-    nh_private_.param("image_encoding", image_encoding_, sensor_msgs::image_encodings::RGB8);
+    nh_private_.param("image_encoding", image_encoding_, std::string("yuv420"));
     if (image_encoding_ != sensor_msgs::image_encodings::RGB8 &&
-        image_encoding_ != sensor_msgs::image_encodings::MONO8 && 
+        // image_encoding_ != sensor_msgs::image_encodings::MONO8 &&
+        // image_encoding_ != "yuv422" &&
+        image_encoding_ != "yuv420" &&
         image_encoding_ != "jpeg") {
       ROS_FATAL_STREAM("Unsupported image encoding: " + image_encoding_);
     }
 
+    // Mapping between image_encoding_ and app_sink_format_
+    // 'tiovxcolorconvert' supports: RGB, NV12
+    if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
+      app_sink_format_ = "RGB";
+    } else if (image_encoding_ == "yuv420") {
+      app_sink_format_ = "NV12";
+    } else if (image_encoding_ == "jpeg") {
+      app_sink_format_ = "";
+    }
+
     camera_info_manager_.setCameraName(camera_name_);
 
     if(camera_info_manager_.validateURL(camera_info_url_)) {
@@ -125,32 +137,24 @@ namespace gscam {
       return false;
     }
 
-    // Create RGB sink
+    // Create app sink
     sink_ = gst_element_factory_make("appsink",NULL);
     GstCaps * caps = gst_app_sink_get_caps(GST_APP_SINK(sink_));
 
-#if (GST_VERSION_MAJOR == 1)
     // http://gstreamer.freedesktop.org/data/doc/gstreamer/head/pwg/html/section-types-definitions.html
-    if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
-        caps = gst_caps_new_simple( "video/x-raw", 
-            "format", G_TYPE_STRING, "RGB",
-            NULL); 
-    } else if (image_encoding_ == sensor_msgs::image_encodings::MONO8) {
-        caps = gst_caps_new_simple( "video/x-raw", 
-            "format", G_TYPE_STRING, "GRAY8",
-            NULL); 
-    } else if (image_encoding_ == "jpeg") {
-        caps = gst_caps_new_simple("image/jpeg", NULL, NULL);
+    if (image_encoding_ == "jpeg") {
+      caps = gst_caps_new_simple("image/jpeg", NULL, NULL);
     }
-#else
-    if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
-        caps = gst_caps_new_simple( "video/x-raw-rgb", NULL,NULL); 
-    } else if (image_encoding_ == sensor_msgs::image_encodings::MONO8) {
-        caps = gst_caps_new_simple("video/x-raw-gray", NULL, NULL);
-    } else if (image_encoding_ == "jpeg") {
-        caps = gst_caps_new_simple("image/jpeg", NULL, NULL);
+    else {
+      ROS_INFO_STREAM("app_sink_format_ = "<<app_sink_format_);
+      caps = gst_caps_new_simple( "video/x-raw",
+          "format", G_TYPE_STRING, app_sink_format_.c_str(),
+          "framerate", GST_TYPE_FRACTION, set_framerate_, 1,
+          "pixel-aspect-ratio", GST_TYPE_FRACTION, 1, 1,
+          "width", G_TYPE_INT, set_width_,
+          "height", G_TYPE_INT, set_height_,
+          NULL);
     }
-#endif
 
     gst_app_sink_set_caps(GST_APP_SINK(sink_), caps);
     gst_caps_unref(caps);
@@ -220,10 +224,10 @@ namespace gscam {
 
     // Create ROS camera interface
     if (image_encoding_ == "jpeg") {
-        jpeg_pub_ = nh_.advertise<sensor_msgs::CompressedImage>("camera/image_raw/compressed",1);
-        cinfo_pub_ = nh_.advertise<sensor_msgs::CameraInfo>("camera/camera_info",1);
+        jpeg_pub_ = nh_.advertise<sensor_msgs::CompressedImage>(camera_name_ + "/image_raw/compressed",1);
+        cinfo_pub_ = nh_.advertise<sensor_msgs::CameraInfo>(camera_name_ + "/camera_info",1);
     } else {
-        camera_pub_ = image_transport_.advertiseCamera("camera/image_raw", 1);
+        camera_pub_ = image_transport_.advertiseCamera(camera_name_ + "/image_raw", 1);
     }
 
     return true;
@@ -262,13 +266,12 @@ namespace gscam {
     }
     ROS_INFO("Started stream.");
 
-    // Poll the data as fast a spossible
-    while(ros::ok()) 
+    // Poll the data as fast as possible
+    while(ros::ok())
     {
       // This should block until a new frame is awake, this way, we'll run at the
       // actual capture framerate of the device.
       // ROS_DEBUG("Getting data...");
-#if (GST_VERSION_MAJOR == 1)
       GstSample* sample = gst_app_sink_pull_sample(GST_APP_SINK(sink_));
       if(!sample) {
         ROS_ERROR("Could not get gstreamer sample.");
@@ -281,26 +284,10 @@ namespace gscam {
       gst_memory_map(memory, &info, GST_MAP_READ);
       gsize &buf_size = info.size;
       guint8* &buf_data = info.data;
-#else
-      GstBuffer* buf = gst_app_sink_pull_buffer(GST_APP_SINK(sink_));
-      guint &buf_size = buf->size;
-      guint8* &buf_data = buf->data;
-#endif
       GstClockTime bt = gst_element_get_base_time(pipeline_);
       // ROS_INFO("New buffer: timestamp %.6f %lu %lu %.3f",
       //         GST_TIME_AS_USECONDS(buf->timestamp+bt)/1e6+time_offset_, buf->timestamp, bt, time_offset_);
 
-
-#if 0
-      GstFormat fmt = GST_FORMAT_TIME;
-      gint64 current = -1;
-
-       Query the current position of the stream
-      if (gst_element_query_position(pipeline_, &fmt, &current)) {
-          ROS_INFO_STREAM("Position "<<current);
-      }
-#endif
-
       // Stop on end of stream
       if (!buf) {
         ROS_INFO("Stream ended.");
@@ -311,11 +298,7 @@ namespace gscam {
 
       // Get the image width and height
       GstPad* pad = gst_element_get_static_pad(sink_, "sink");
-#if (GST_VERSION_MAJOR == 1)
       const GstCaps *caps = gst_pad_get_current_caps(pad);
-#else
-      const GstCaps *caps = gst_pad_get_negotiated_caps(pad);
-#endif
       GstStructure *structure = gst_caps_get_structure(caps,0);
       gst_structure_get_int(structure,"width",&width_);
       gst_structure_get_int(structure,"height",&height_);
@@ -325,11 +308,7 @@ namespace gscam {
       sensor_msgs::CameraInfoPtr cinfo;
       cinfo.reset(new sensor_msgs::CameraInfo(cur_cinfo));
       if (use_gst_timestamps_) {
-#if (GST_VERSION_MAJOR == 1)
           cinfo->header.stamp = ros::Time(GST_TIME_AS_USECONDS(buf->pts+bt)/1e6+time_offset_);
-#else
-          cinfo->header.stamp = ros::Time(GST_TIME_AS_USECONDS(buf->timestamp+bt)/1e6+time_offset_);
-#endif
       } else {
           cinfo->header.stamp = ros::Time::now();
       }
@@ -346,14 +325,19 @@ namespace gscam {
           cinfo_pub_.publish(cinfo);
       } else {
           // Complain if the returned buffer is smaller than we expect
-          const unsigned int expected_frame_size =
-              image_encoding_ == sensor_msgs::image_encodings::RGB8
-              ? width_ * height_ * 3
-              : width_ * height_;
-
-          if (buf_size < expected_frame_size) {
-              ROS_WARN_STREAM( "GStreamer image buffer underflow: Expected frame to be "
-                      << expected_frame_size << " bytes but got only "
+          unsigned int expected_frame_size;
+          if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
+              expected_frame_size = width_ * height_ * 3;
+          }
+          else if (image_encoding_ == "yuv420") {
+              expected_frame_size = width_ * height_ * 1.5;
+          }
+          else {
+              expected_frame_size = width_ * height_;
+          }
+          if (buf_size != expected_frame_size) {
+              ROS_WARN_STREAM( "GStreamer image buffer underflow or overflow: Expected frame to be "
+                      << expected_frame_size << " bytes but got "
                       << (buf_size) << " bytes. (make sure frames are correctly encoded)");
           }
 
@@ -374,12 +358,12 @@ namespace gscam {
           // we can free the buffer allocated by gstreamer
           if (image_encoding_ == sensor_msgs::image_encodings::RGB8) {
               img->step = width_ * 3;
+          } else if (image_encoding_ == "yuv420") { // NV12
+              img->step = width_;
           } else {
               img->step = width_;
           }
-          std::copy(
-                  buf_data,
-                  (buf_data)+(buf_size),
+          std::copy(buf_data, (buf_data)+(buf_size),
                   img->data.begin());
 
           // Publish the image/info
@@ -388,11 +372,11 @@ namespace gscam {
 
       // Release the buffer
       if(buf) {
-#if (GST_VERSION_MAJOR == 1)
         gst_memory_unmap(memory, &info);
         gst_memory_unref(memory);
-#endif
-        gst_buffer_unref(buf);
+        // https://github.com/clydemcqueen/gscam2/issues/9
+        // gst_buffer_unref(buf);
+        gst_sample_unref(sample);
       }
 
       ros::spinOnce();
